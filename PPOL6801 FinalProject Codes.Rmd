---
title: "Sephora Product Review Sentiment Analysis"
subtitle: "Examning how review characteristics affect the emotional tone in skincare product reviews?"
author: "Amber"
date: "May 2, 2025"
output: html_document
---

## Introduction

### Background

In 2023, 32% of global beauty and personal care sales were made online, up from 21% in 2019 (Statista, 2024). As online shopping continues to gain popularity, beauty companies and brands are increasingly leveraging data analytics to better understand their consumers, develop tailored marketing strategies, and drive innovation. In fact, over 65% of beauty brands reported using AI and data analytics to personalize customer experiences in 2023 (Forbes, How AI Is Transforming The Beauty Industry, 2023). With 82% seek out customer reviews before purchasing a beauty or grooming product (Space48, Beauty, grooming & cosmetics online shopping consumer survey findings, 2023) and 97% of consumers stating that online reviews influence their beauty product purchases (PowerReviews, Beauty Shopper Study, 2023), it has become more important than ever for beauty marketers to align their communications and marketing strategies with consumer preferences and mindsets.

Business analysts are utilizing consumer activity and consumption data to draw inferences and perform predictive analysis, particularly in three key areas: (1) market trends, (2) consumer preferences, and (3) online engagement.

**1. Market Trend**

Leveraging robust datasets available online across different brands and types of products now enables brands to anticipate emerging beauty trends in the market, giving them a more holistic picture of leading products  with further analysis on what is the newest driving force of consumption and allowing them to proactively develop products that meet evolving consumer desires.

**2. Consumer preferences**

By analyzing consumer purchase history, beauty brands can gain deep insights into what drives purchasing decisions. This includes understanding preferences for product ingredients, pricing, and brand loyalty. Additionally, tracking demographic and geographic preferences enables brands to tailor their strategies for different consumer segments, ensuring that their products align with the diverse needs and expectations of their target audience.

**3. Online engagement**

User interactions—likes, shares, comments, and reviews—serve as key indicators of brand performance and consumer sentiment. By analyzing engagement metrics across social media and e-commerce platforms, beauty brands can track trending products and identify potential pain points. Additionally, sentiment analysis and recommendation algorithms help brands address concerns, optimize product exposure, and foster deeper consumer interactions.

### Overview of Sephora Online Shop

Sephora’s online store serves as a premier platform for personal care and beauty products, offering a diverse and extensive choices from both global luxury brands and emerging labels. It offers over 340 brands and 45,000 products, including skincare, makeup, haircare, and fragrance (Statista, 2023). Sephora attracts over 50 million unique visitors to its website each month globally (Similarweb, 2024). With millions of active consumers regularly sharing their experiences through detailed reviews, Sephora provides a rich source of user-generated content that captures authentic customer sentiments and preferences. 

The platform’s vast selection of skincare products across various categories ensures a comprehensive representation of consumer behavior, making it an ideal dataset for analysis. This combination of high engagement, product variety, and brand diversity positions Sephora’s online shop as a valuable resource for data-driven insights into skincare trends, customer satisfaction drivers, and market dynamics.


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, eval = TRUE, warning = FALSE)
rm(list=ls())
knitr::opts_knit$set(root.dir = "~/Desktop/Grad/25Spring/Text As Data/PPOL6801 FinalProject")
getwd()

# Load required packages
pacman::p_load(tidyverse, quanteda, quanteda.corpora, quanteda.textstats, quanteda.textmodels, dplyr, textclean, topicmodels, tidytext, modelsummary, stringr)
```

```{r load}
reviews <- read.csv("[Import Dataset]reviews_0-250.csv")
```

```{r subset}

# Get a subset of 10000 observations
set.seed(123)
reviews_subset <- reviews %>% slice_sample(n = 10000)

# Classify reviews into two categories
reviews_subset <- reviews_subset %>%
    mutate(review_type = case_when(
    rating %in% c(4, 5) ~ "Positive",
    rating %in% c(1, 2, 3) ~ "Non-positive"
  ))

# Check the class distribution
prop.table(table(reviews_subset$review_type))

# Only keep texts and categories for simplicity
reviews_samp <- reviews_subset %>%
  select(review_text, review_title, review_type) 

```

## Descriptive statistics

### Brand-level

```{r brand}

samp_brand <- reviews_subset %>%
    select(review_text, review_title, review_type, brand_name) 

# Count the total number of reviews per brand
brand_total <- samp_brand %>%
  group_by(brand_name) %>%
  summarise(total_reviews = n())

# Count the number of positive and negative reviews per brand
brand_reviews <- samp_brand %>%
  group_by(brand_name, review_type) %>%
  summarise(count = n()) %>%
  ungroup()

# Merge the total reviews with the positive/negative counts
brand_reviews <- merge(brand_reviews, brand_total, by = "brand_name")

# Calculate the proportion of positive and negative reviews
brand_reviews <- brand_reviews %>%
  mutate(proportion = count / total_reviews)

# Find the top 5 brands with the highest proportion of positive reviews
toppos_prop_brand <- brand_reviews %>%
  filter(review_type == "Positive") %>%
  arrange(desc(proportion)) %>%
  slice_head(n = 5)

# Find the top 5 brands with the highest proportion of non-positive reviews
topnonpos_prop_brand <- brand_reviews %>%
  filter(review_type == "Non-positive") %>%
  arrange(desc(proportion)) %>%
  slice_head(n = 5)

print(toppos_prop_brand)
print(topnonpos_prop_brand)

```

### Individual-level

```{r individual}

samp_ind <- reviews_subset %>%
  filter(skin_type != "") %>%
  select(review_text, review_title, review_type, skin_type) 

# Count the total number of reviews per brand
ind_total <- samp_ind %>%
  group_by(skin_type) %>%
  summarise(total_reviews = n())

# Count the number of positive and negative reviews per brand
ind_reviews <- samp_ind %>%
  group_by(skin_type, review_type) %>%
  summarise(count = n()) %>%
  ungroup()

# Merge the total reviews with the positive/negative counts
ind_reviews <- merge(ind_reviews, ind_total, by = "skin_type")

# Calculate the proportion of positive and negative reviews
ind_reviews <- ind_reviews %>%
  mutate(proportion = count / total_reviews)

# Find the top 5 brands with the highest proportion of positive reviews
toppos_prop_ind <- ind_reviews %>%
  filter(review_type == "Positive") %>%
  arrange(desc(proportion)) %>%
  slice_head(n = 5)

# Find the top 5 brands with the highest proportion of non-positive reviews
topnonpos_prop_ind <- ind_reviews %>%
  filter(review_type == "Non-positive") %>%
  arrange(desc(proportion)) %>%
  slice_head(n = 5)

print(toppos_prop_ind)
print(topnonpos_prop_ind)

# Visualization

ind_combined <- bind_rows(toppos_prop_ind, topnonpos_prop_ind)

ggplot(ind_combined, aes(x = skin_type, y = proportion, fill = review_type)) +
  geom_bar(stat = "identity", position = position_dodge(width = 0.9)) +
  geom_text(
    aes(label = round(proportion, 2)),
    position = position_dodge(width = 0.9),
    vjust = -0.3,
    size = 3.5
  ) +
  labs(
    title = "Proportion of Positive and Non-Positive Reviews by Skin Type",
    subtitle = "People with combination skin leave more positive reviews, 
while those with dry skin leave more negative ones.",
    x = "Skin Type",
    y = "Proportion",
    fill = "Review Type"
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(face = "bold", size = 14),
    plot.subtitle = element_text(size = 11),
    axis.text.x = element_text(size = 10),
    axis.title = element_text(size = 11)
  )

```


## Pre-processing

```{r preprocessing}

## Some pre-processing steps (remove common English contractions and clean texts)
reviews_samp$review_text <- gsub("'s|'m|'re|'d|'ve|'ll|n't|’s|’m|’re|’d|’ve|’ll|n’t", "", reviews_samp$review_text)

reviews_samp$review_text <- reviews_samp$review_text %>%
  replace_contraction() %>%  
  replace_word_elongation() %>%  
  replace_symbol() %>%  
  replace_number() %>%  
  replace_non_ascii() 

pos_reviews <- reviews_samp[reviews_samp$review_type == "Positive", ]
nonpos_reviews <- reviews_samp[reviews_samp$review_type == "Non-positive", ]

## Tokenization & convert to a document-feature matrix (DFM) & trimming

reviews_dfm <- tokens(reviews_samp$review_text, remove_punct = TRUE, remove_numbers = TRUE) %>%
  tokens_tolower() %>%
  dfm() %>%
  dfm_wordstem() %>%
  dfm_remove(stopwords("en")) # %>%
# dfm_trim(min_docfreq = 0.001, max_docfreq = 0.999, docfreq_type = "prop", verbose = TRUE)

pos_dfm <- tokens(pos_reviews$review_text, remove_punct = TRUE, remove_numbers = TRUE) %>%
  tokens_tolower() %>%
  dfm() %>%
  dfm_wordstem() %>%
  dfm_remove(stopwords("en")) # %>%
# dfm_trim(min_docfreq = 0.001, max_docfreq = 0.999, docfreq_type = "prop", verbose = TRUE)

nonpos_dfm <- tokens(nonpos_reviews$review_text, remove_punct = TRUE, remove_numbers = TRUE) %>%
  tokens_tolower() %>%
  dfm() %>%
  dfm_wordstem() %>%
  dfm_remove(stopwords("en")) # %>%
# dfm_trim(min_docfreq = 0.001, max_docfreq = 0.999, docfreq_type = "prop", verbose = TRUE)

```

## Review Word Clouds

```{r wordclouds}

# Load package necessary to create word clouds
pacman::p_load(quanteda.textplots)

# Create several word clouds for reviews (overall, positive, non-positive)

reviews_wordcloud <- dfm_remove(reviews_dfm, c("skin", "product", "feel", "use", "just", "veri"))

reviewsWordcloud <- textplot_wordcloud(reviews_wordcloud, random_order = FALSE,
                   rotation = .25, max_words = 100,
                   min_size = 0.5, max_size = 2.8,
                   colors = RColorBrewer::brewer.pal(8, "Dark2"))
```

## Differences in Vocabulary Between Positive and Non-Positive Reviews

### TF-IDF: 
#### What are the most important and distinctive words in positive and non-positive reviews?

```{r tf-idf}

# Combine two dfms and tag documents with their group
pos_dfm$group <- "positive"
nonpos_dfm$group <- "non_positive"

# Combine into one dfm
combined_dfm <- rbind(pos_dfm, nonpos_dfm)

# Compute TF-IDF
tfidf_dfm <- dfm_tfidf(combined_dfm)

# Split back by group
tfidf_matrix <- convert(tfidf_dfm, to = "data.frame")
doc_groups <- docvars(tfidf_dfm, "group")

# Compute average tf-idf per term by group
tfidf_by_group <- tfidf_matrix %>%
  mutate(group = doc_groups) %>%
  group_by(group) %>%
  summarise(across(-doc_id, mean)) %>%
  t() %>%
  as.data.frame()

# Rename and clean
colnames(tfidf_by_group) <- tfidf_by_group[1,]
tfidf_by_group <- tfidf_by_group[-1,]
tfidf_by_group$term <- rownames(tfidf_by_group)

# Sort top TF-IDF terms in each group
top_pos_tfidf <- tfidf_by_group %>%
  arrange(desc(positive)) %>%
  slice(1:20) %>%
  select(term,positive_tfidf = positive)

top_nonpos_tfidf <- tfidf_by_group %>%
  arrange(desc(non_positive)) %>%
  slice(1:20) %>%
  select(term, nonpositive_tfidf = non_positive)

print(top_pos_tfidf)
print(top_nonpos_tfidf)

```
Many terms are generic skincare words (skin, face, product, use, skin), which is typical due to TF-IDF being influenced by frequency within category.

**For positive reviews**
Words like "love", "feel", "moistur", and "like" suggest:
- Positive emotional responses.
- Focus on hydration and skin texture — common satisfaction points in skincare

**For non-positive reviews**
Words like "just", "doe", "realli", and "tri" suggest:
- Expressions of disappointment or unmet expectations.
- Example phrases: "I just didn’t like it", "doesn’t work", "I really wanted this to help", "I tried but...".

### Log-Ratio of Term Probabilities
#### How much more (or less) frequent a word is in positive reviews vs. non-positive reviews?

```{r logratio}

# ------------- Step 1: Calculate log-ratio of term probabilities

# Extract feature names (keywords) from each dfm
pos_terms <- featnames(pos_dfm)
non_pos_terms <- featnames(nonpos_dfm)

# Total number of terms in each dfm
pos_total <- sum(pos_dfm)
non_pos_total <- sum(nonpos_dfm)

# Term frequencies with smoothing (+1 to avoid division by zero)
pos_freq <- colSums(pos_dfm) + 1
non_pos_freq <- colSums(nonpos_dfm) + 1

# Calculate term probabilities
pos_prob <- pos_freq / pos_total
non_pos_prob <- non_pos_freq / non_pos_total

# Create a unified set of all terms from both dfms
all_terms <- union(pos_terms, non_pos_terms)

# Ensure both probability vectors include all terms (fill missing terms with smoothing)
pos_prob_full <- pos_prob[all_terms]
non_pos_prob_full <- non_pos_prob[all_terms]

pos_prob_full[is.na(pos_prob_full)] <- 1 / pos_total
non_pos_prob_full[is.na(non_pos_prob_full)] <- 1 / non_pos_total

# Compute log-ratio of term probabilities
log_ratio <- log2(pos_prob_full / non_pos_prob_full)

# Create a dataframe to store terms and their log-ratio values
log_ratio_df <- data.frame(
  term = all_terms,
  log_ratio = log_ratio
)

# Sort by absolute value of log-ratio to find most differentiating terms
log_ratio_df <- log_ratio_df %>% arrange(desc(abs(log_ratio)))

# View top 20 keywords with the highest differentiation between categories
head(log_ratio_df, 20)

# ------------- Step 2: Visualize the log-ratio result

# Top 10 terms more frequent in positive reviews
top_positive <- log_ratio_df %>%
  filter(log_ratio > 0) %>%
  arrange(desc(log_ratio)) %>%
  slice(1:10)

# Top 10 terms more frequent in non-positive reviews
top_non_positive <- log_ratio_df %>%
  filter(log_ratio < 0) %>%
  arrange(log_ratio) %>%   
  slice(1:10)

# Combine them
top_terms_balanced <- bind_rows(top_positive, top_non_positive)


ggplot(top_terms_balanced, aes(x = reorder(term, log_ratio), y = log_ratio, fill = log_ratio > 0)) +
  geom_bar(stat = "identity") +
  coord_flip() +
  scale_fill_manual(values = c("TRUE" = "steelblue", "FALSE" = "tomato"),
                    labels = c("Positive", "Non-Positive")) +
  labs(title = "Top Differentiating Terms by Log-Ratio",
       x = "",
       y = "Log2 Ratio (Positive / Non-Positive)",
       fill = "More Frequent In") +
  theme_minimal()

```
This bar chart highlights the top differentiating keywords between positive and non-positive skincare product reviews based on the log2 ratio of term probabilities.

**For positive reviews**
These terms reflect positive emotions, desirable skincare outcomes (like "radiant", "clearer", "healthy"), and experiences of self-care or luxury ("spa", "treat"). Words like obsess and hook suggest strong customer enthusiasm.

This indicates that consumers highly value products that deliver visible results while also offering a sense of pampering. Brands can leverage this by (1) highlighting transformative effects (e.g., "Get radiant, clearer skin"), (2) positioning products as part of a self-care routine with a focus on wellness (e.g., "Treat yourself to daily luxury"), and (3) pivoting to a concept of maintaining long-term skin health (e.g., "Nourish your skin for a healthier tomorrow" or "Support your skin’s natural balance").

**For non-positive reviews**
Negative reviews frequently mention issues related to skin irritation, inconsistent product quality, and unmet expectations. These terms convey dissatisfaction, poor product performance, or negative experiences (e.g., "refund", "trash", "burnt", "splotch"). Emotional tones include disappointment (meh), frustration (blame), and rejection.

This indicates that brands should (1) prioritize product safety and clearly communicate usage instructions to avoid adverse effects like "burnt" or "splotchy" skin and (2) Customer service teams can proactively manage dissatisfaction by offering solutions like optimizing refund policies.

## Sentiment Analysis

### AFINN

```{r afinn}
pacman::p_load(quanteda, textdata)

afinn <- lexicon_afinn()

# Ensure all terms are lowercase to match DFM features
afinn$word <- tolower(afinn$word)

# Match DFM features with AFINN lexicon
matched_reviewdfm <- dfm_match(reviews_dfm, features = afinn$word)

# Create a named vector of AFINN scores
afinn_vector <- afinn$value
names(afinn_vector) <- afinn$word

# Ensure feature order matches
matched_features <- colnames(matched_reviewdfm)
score_vector <- afinn_vector[matched_features]

# Convert to matrix and multiply
sentiment_scores <- as.numeric(matched_reviewdfm %*% score_vector)

# add scores back to the data
reviews_sentiment <- data.frame(
  doc_id = docnames(matched_reviewdfm),
  sentiment = sentiment_scores
)

# Normalize score

## Count tokens (words) in each review
token_counts <- ntoken(reviews_dfm) 

## Add token count to sentiment dataframe (make sure order is preserved!)
reviews_sentiment$token_count <- token_counts

## Compute normalized sentiment score
reviews_sentiment <- reviews_sentiment %>%
  mutate(norm_sentiment = sentiment / token_count)

# Add row index to both datasets
reviews_sentiment <- reviews_sentiment %>% mutate(row_id = row_number())
reviews_subset <- reviews_subset %>% mutate(row_id = row_number())

# Merge to the original dataset
reviews_subset <- left_join(reviews_subset, reviews_sentiment %>% select(row_id, sentiment, norm_sentiment), by = "row_id")

```

## LDA Topic Modeling

```{r lda}

# Fit LDA topic modeling for all reviews 

# Clean dfm - remove some common topic-unrelated words
custom_stopwords <- c("use", "like", "product", "feel", "love", "good", "realli", "get", "make", "tri", "work", "veri", "just", "day", "look", "even", "great", "much", "becaus", "never", "skin", "give", "now", "littl", "can", "one", "also", "think", "although")
dfm_cleaned <- dfm_remove(reviews_dfm, pattern = custom_stopwords)

# Convert dfm to dtm
dtm_cleaned <- convert(dfm_cleaned, to = "topicmodels")

# Apply LDA
reviews_lda <- LDA(dtm_cleaned, k = 4, control = list(seed = 1234), alpha = 0.1, eta = 0.1) 

# Identify the most representative words for each topic

##  ---- STEP 1: Extract Word-Topic Probabilities ("Beta")  

reviews_topics <- tidy(reviews_lda, matrix = "beta") # Extract word-topic probabilities
head(reviews_topics)

## ----- STEP 2: Visualize the Top Words in Each Topic  

reviews_top_terms <- reviews_topics %>%
  group_by(topic) %>%
  slice_max(beta, n = 20) %>% 
  # slice_max(beta, n = 10) %>% 
  ungroup() %>%
  arrange(topic, -beta)

## Plot top words per topic
reviews_top_terms %>%
  mutate(term = reorder_within(term, beta, topic)) %>%
  ggplot(aes(beta, term, fill = factor(topic))) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~ topic, scales = "free") +
  scale_y_reordered() +
  labs(title = "Top 20 Words in Each Topic", x = "Word Probability (Beta)", y = "Word") +
  theme_minimal()

# Assign each review with the most dominant topic

topic_labels <- c("Moisterization", "Problematic Skin (Acne/Sensitivity)", 
                  "Texture, Fragrance & Makeup", "Purchase Experience & Satisfaction")

gamma <- tidy(reviews_lda, matrix = "gamma") # Get gamma for each review

# Get the dominant topic per document
dominant_topic <- gamma %>%
  group_by(document) %>%
  slice_max(order_by = gamma, n = 1) %>%
  ungroup() %>%
  mutate(dominant_label = topic_labels[topic])

# Get document ID for my original dataset for merging purpose
reviews_subset <- reviews_subset %>%
  mutate(document = paste0("text", row_number()))

# Combine dominant topic for each document to my original dataset
reviews_subset <- left_join(reviews_subset, 
                             dominant_topic %>% select(document, dominant_label), 
                             by = "document")

```
Topic 1: Moisterization
- Top words: moistur, dri, well, smell, appli, leav, soft, night, definit
- Likely Themes: How moisturizing the product feels; dry skins.

Topic 2: Problematic Skin (Acne/Sensitivity)
- Top words: face, moistur, acn, sensit, cleanser, cream, oil, clean, smell
- Likely Themes: Usage of product on face, especially for acne-prone or sensitive skin types. 

Topic 3: Texture, Fragrance & Makeup 
- Top words: face, cream, textur, makeup, recommend, super, nice, scent, notic, eye, smooth
- Likely Themes: Product texture and appearance with makeup.

Topic 4: Purchase Experience & Satisfaction
- Top words: hydr, smooth, help, mask, purchas, sampl, price, got, order, want, cleanser
- Likely Themes: Consumer satisfaction, purchase journey, price perception, and delivery. (Mentions of `got`, `purchas`, `sampl`, and `price` make the focus centered around shopping experience + satisfaction.)

### Ratings & sentiment scores among different topics

```{r lda6}

# Keep only the columns we need for clarity
reviews_samp_topic <- reviews_subset %>%
  select(document, rating, brand_name, review_type, dominant_label, norm_sentiment)

# Look at the average ratings for each topic
reviews_samp_topic %>%
  group_by(dominant_label) %>%
  filter(!is.na(dominant_label)) %>% # Eliminate missing reviews
  summarise(
    count = n(),
    avg_rating = mean(rating, na.rm = TRUE),
  ) %>%
  arrange(desc(avg_rating))

# Look at the average normalized sentiment scores (using AFINN)

reviews_samp_topic %>%
  group_by(dominant_label) %>%
  filter(!is.na(dominant_label)) %>% # Eliminate missing reviews
  summarise(
    count = n(),
    avg_sentiment_score = mean(norm_sentiment, na.rm = TRUE),
  ) %>%
  arrange(desc(avg_sentiment_score))

# Visualization

reviews_samp_topic_visual <- reviews_samp_topic %>%
  group_by(dominant_label)%>%
  summarise(
    avg_rating = mean(rating, na.rm = TRUE),
    avg_sentiment = mean(norm_sentiment, na.rm = TRUE)
  ) %>%
  pivot_longer(cols = c(avg_rating, avg_sentiment),
               names_to = "metric",
               values_to = "value")

reviews_samp_topic_visual$metric <- recode(reviews_samp_topic_visual$metric,
                            "avg_rating" = "Rating",
                            "avg_sentiment" = "Sentiment Score")

reviews_samp_topic_visual <- reviews_samp_topic_visual%>% filter(!is.na(dominant_label))


# Barplot
ggplot(reviews_samp_topic_visual, aes(x = dominant_label, y = value, fill = metric)) +
  geom_bar(stat = "identity", position = position_dodge(width = 0.9)) +
  geom_text(
    aes(label = round(value, 2)),
    position = position_dodge(width = 0.9),
    vjust = -0.3,
    size = 3
  ) +
  labs(
    title = "Average Rating and Sentiment by Skincare Review Topic",
    subtitle = "Comparison across four review themes from LDA: Texture, Fragrance & Makeup always ranks top",
    x = "",
    y = "Average Value",
    fill = "Measure"
  ) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 30, hjust = 1))
```


## Linear regression

```{r}

# Add more variables needed for regression

## Length of each review 

token_count <- ntoken(reviews_dfm)  # vector of token counts per doc
reviews_subset$token_count <- token_count

## Skin Type
reviews_subset$skin_type[reviews_subset$skin_type == ""] <- NA

## Social Media 
social_keywords <- c(
  "social media",
  "instagram",
  "tiktok",
  "youtube",
  "reddit",
  "influencer",
  "viral",
  "trending",
  "reel",
  "hashtag",
  "shared online",
  "went viral",
  "buzz",
  "in my feed",
  "algorithm",
  "recommendation",
  "pinterest",
  "snapchat"
)

reviews_social <- reviews_subset %>%
  filter(str_detect(tolower(review_text), str_c(social_keywords, collapse = "|")))

reviews_subset <- reviews_subset %>%
  mutate(mentions_social_media = str_detect(tolower(review_text), str_c(social_keywords, collapse = "|")))

# Keeps only variables needed for regression

reviews_lr <- reviews_subset %>%
  select(rating, price_usd, dominant_label, norm_sentiment, skin_type, token_count, mentions_social_media) %>%
  drop_na()

# Fit a regression model 

lm_model <- lm(norm_sentiment ~ token_count + price_usd + skin_type + dominant_label + mentions_social_media, data = reviews_lr)
summary(lm_model)
```

```{r export}

# export final dataset
write.csv(reviews_lr, "reviews_lr.csv", row.names = FALSE)

```
